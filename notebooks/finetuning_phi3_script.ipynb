{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33c56a4648143d8a5af3ac2939b7106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "checkpoint = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                             device_map=device,\n",
    "                                             attn_implementation='flash_attention_2',\n",
    "                                             cache_dir='/mnt/esperanto/et/huggingface/hub',\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_lora_fp32(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        if 'lora' in n and p.requires_grad:\n",
    "            p.data = p.data.to(torch.float32)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,801,088 || all params: 3,824,880,640 || trainable%: 0.0994\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules = [\"o_proj\", \"qkv_proj\", \"gate_proj\", \"down_proj\"]\n",
    ")\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "model = get_peft_model(model, lora_config)\n",
    "model = cast_lora_fp32(model)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sample, tokenizer):\n",
    "    system_prompt = \"You are an AI model designed to help visually impaired people. Your task is to provide a comprehensive description of the image, locating important objects to guide disabled people through the scene.\"\n",
    "\n",
    "    boxes = [row for row in sample['segments_postprocessed'][0]['boxes']]\n",
    "    boxes = [str([round(x,2) for x in row]) for row in boxes]\n",
    "    labels = sample['segments_postprocessed'][0]['labels']\n",
    "    box_prompt = '\\n'.join(sorted([a + ' ' + b for a,b in zip(labels, boxes)]))\n",
    "\n",
    "    title = sample['title']\n",
    "    question_prompt = f\"Below is a description of a {title} scene, along with a list of objects present in the scene along with their coordinates following the format 'object [x_min, y_min, x_max, y_max]'. Provide a descriptive paragraph using a human-like description, do not mention coordinates. Only use the position information and infer from it, do not add any comment or guess. Remain factual and avoid unnecessary embellishments, keep it simple.\"\n",
    "\n",
    "    descriptive_text = sample['generated_descriptive_text']\n",
    "\n",
    "    sample_prompt = f\"\"\"<|system|>\n",
    "{system_prompt}<|end|>\n",
    "<|user|>\n",
    "{question_prompt}\n",
    "{box_prompt}<|end|>\n",
    "<|assistant|>\n",
    "{descriptive_text}<|end|>\"\"\"\n",
    "\n",
    "    inputs = tokenizer(sample_prompt)\n",
    "    \n",
    "    sample['full_sample'] = sample_prompt\n",
    "    sample['input_ids'] = inputs.input_ids\n",
    "    sample['attention_mask'] = inputs.attention_mask\n",
    "    sample['labels'] = inputs.input_ids.copy()\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {'train': \"../data/train2014_descriptive_texts.json\", 'val': \"../data/val2014_descriptive_texts.json\"}\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files=data_files)\n",
    "datasets = datasets.map(lambda x: prepare_data(x, tokenizer))\n",
    "\n",
    "train_data, val_data = datasets['train'], datasets['val'].select(list(range(1_000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/et/miniconda3/envs/visual_description/lib/python3.12/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "args_output_dir = \"../models/phi3-mini-VD-v2\"\n",
    "args_max_steps = 20_000\n",
    "args_eval_freq_default = 1_000\n",
    "args_log_freq_default = 1_000\n",
    "args_save_freq_default = 1_000\n",
    "args_batch_size = 1\n",
    "args_learning_rate = 8e-5\n",
    "args_lr_scheduler_type=\"cosine\"\n",
    "args_num_warmup_steps = 200\n",
    "args_gradient_accumulation_steps_default = 1\n",
    "args_weight_decay = 0.05\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=args_output_dir,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        dataloader_drop_last=True,\n",
    "        max_steps=args_max_steps,\n",
    "        eval_steps=args_eval_freq_default,\n",
    "        save_steps=args_save_freq_default,\n",
    "        logging_steps=args_log_freq_default,\n",
    "        per_device_train_batch_size=args_batch_size,\n",
    "        per_device_eval_batch_size=args_batch_size,\n",
    "        learning_rate=args_learning_rate,\n",
    "        lr_scheduler_type=args_lr_scheduler_type,\n",
    "        warmup_steps=args_num_warmup_steps,\n",
    "        gradient_accumulation_steps=args_gradient_accumulation_steps_default,\n",
    "        fp16=True,\n",
    "        weight_decay=args_weight_decay,\n",
    "        run_name=\"phi3-mini-VD-v2\",\n",
    "        report_to='wandb',\n",
    "        #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msade-adrien\u001b[0m (\u001b[33mesperanto\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/datascience1/Adrien/visual_description/notebooks/wandb/run-20240711_103714-0l0ppyjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esperanto/huggingface/runs/0l0ppyjn' target=\"_blank\">phi3-mini-VD-v2</a></strong> to <a href='https://wandb.ai/esperanto/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esperanto/huggingface' target=\"_blank\">https://wandb.ai/esperanto/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esperanto/huggingface/runs/0l0ppyjn' target=\"_blank\">https://wandb.ai/esperanto/huggingface/runs/0l0ppyjn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20000/20000 1:06:39, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.667700</td>\n",
       "      <td>0.586104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.569576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.558359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.551056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>0.546547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.543065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.541500</td>\n",
       "      <td>0.537967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.534940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.532368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.529203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.527550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.525790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.523222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.522159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.521217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.520775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.520438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.520245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.520212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20000, training_loss=0.5386242462158203, metrics={'train_runtime': 4004.749, 'train_samples_per_second': 4.994, 'train_steps_per_second': 4.994, 'total_flos': 2.9345980575246336e+17, 'train_loss': 0.5386242462158203, 'epoch': 1.64866870002473})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual_description",
   "language": "python",
   "name": "visual_description"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
