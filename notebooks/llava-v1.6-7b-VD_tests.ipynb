{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-15 15:04:17,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from llava.mm_utils import get_model_name_from_path, tokenizer_image_token\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.constants import IMAGE_TOKEN_INDEX\n",
    "from llava.eval.run_llava import eval_model\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/llava-v1.6-vicuna-7b-VD/checkpoint-12000\"\n",
    "device = 'cuda:0'\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=get_model_name_from_path(model_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a descriptive paragraph of the crowded bar scene:\n",
      "\n",
      "You are standing in a bustling bar with a long counter stretching across the room. The counter is lined with bottles and glasses, and there are several menus displayed on it. Above the counter, there are three light fixtures hanging from the ceiling. To your left, you see a group of people gathered around the counter, while to your right, there's another group of people seated at tables. The tables are scattered throughout the room, with some near the walls and others in the center of the room. You notice several menus placed on the tables, likely belonging to the patrons. There are also several glasses and bottles scattered around the room, some on the counter and others on the tables. The atmosphere is lively, with many people socializing and enjoying their drinks.\n"
     ]
    }
   ],
   "source": [
    "title = \"crowded bar\"\n",
    "prompt = f\"\"\"USER: You are an AI model designed to help visually impaired people. Your task is to provide a comprehensive description of the image, locating important objects to guide disabled people through the scene.\\nBelow is a {title} scene. Provide a descriptive paragraph using a human-like description. Do not add any comment or guess. Remain factual and avoid unnecessary embellishments, keep it simple.\\n<image> ASSISTANT:\"\"\"\n",
    "image_file = '../data/image_examples/bar.jpeg'\n",
    "\n",
    "raw_image = Image.open(image_file).convert('RGB')\n",
    "image_tensor = image_processor(raw_image, return_tensors='pt')['pixel_values'].to(device).to(torch.float16)\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "                        input_ids,\n",
    "                        images=image_tensor,\n",
    "                        do_sample=False,\n",
    "                        #temperature=0.2,\n",
    "                        max_new_tokens=500,\n",
    "                        )\n",
    "\n",
    "outputs = tokenizer.decode(output_ids[0,:], skip_special_tokens=True).strip()\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as-visual_description",
   "language": "python",
   "name": "as-visual_description"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
